import { promises as fs } from 'fs'
import path from 'path'
import { createHash } from 'crypto'
import { getVectorCache, AIEmbedding } from './vector-cache'
import { pipeline, env, Pipeline } from '@xenova/transformers'
import pdfParse from 'pdf-parse'
import { createWorker, OEM, PSM } from 'tesseract.js'
import { Canvas, createCanvas, Image, ImageData } from 'canvas'
import 'pdfjs-dist/legacy/build/pdf.mjs' // Import for side-effects
import 'pdfjs-dist/legacy/build/pdf.worker.mjs' // Import for side-effects

// Node.js í™˜ê²½ì—ì„œ pdf.jsê°€ í•„ìš”ë¡œ í•˜ëŠ” DOM API ë° í—¬í¼ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
// ì´ëŠ” pdfjs-distì˜ 'node_utils.mjs' í—¬í¼ ìŠ¤í¬ë¦½íŠ¸ì˜ í•µì‹¬ ë¡œì§ì„ ì¬í˜„í•œ ê²ƒì…ë‹ˆë‹¤.
if (typeof window === 'undefined') {
  const globalScope = globalThis as any

  // DOMMatrix í´ë¦¬í•„
  if (!globalScope.DOMMatrix) {
    class DOMMatrix {
      private m: number[]
      constructor(init?: number[] | string) {
        this.m = Array.isArray(init) ? [...init] : [1, 0, 0, 1, 0, 0]
      }
      translate(tx: number, ty: number): DOMMatrix {
        return new DOMMatrix([
          this.m[0],
          this.m[1],
          this.m[2],
          this.m[3],
          this.m[4] + tx * this.m[0] + ty * this.m[2],
          this.m[5] + tx * this.m[1] + ty * this.m[3],
        ])
      }
      // pdf.js ë Œë”ë§ì— í•„ìš”í•œ ë‹¤ë¥¸ DOMMatrix ë©”ì†Œë“œë“¤ì„ ì—¬ê¸°ì— ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    }
    globalScope.DOMMatrix = DOMMatrix
  }

  // node-canvasì˜ Imageì™€ ImageDataë¥¼ ì „ì—­ìœ¼ë¡œ ì„¤ì •
  globalScope.Image = Image
  globalScope.ImageData = ImageData

  // Canvas ê°ì²´ì—ì„œ createImageDataë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë˜í•‘
  const originalCreateCanvas = createCanvas
  ;(globalScope as any).createCanvas = (width: number, height: number) => {
    const canvas = originalCreateCanvas(width, height)
    ;(canvas as any).createImageData = function (
      width: number,
      height: number
    ) {
      return new ImageData(width, height)
    }
    return canvas
  }
}

env.allowLocalModels = true

class NodeCanvasFactory {
  create(width: number, height: number) {
    const canvas = createCanvas(width, height)
    const context = canvas.getContext('2d')
    return {
      canvas,
      context,
    }
  }

  reset(canvasAndContext: any, width: number, height: number) {
    canvasAndContext.canvas.width = width
    canvasAndContext.canvas.height = height
  }

  destroy(canvasAndContext: any) {
    canvasAndContext.canvas.width = 0
    canvasAndContext.canvas.height = 0
    canvasAndContext.canvas = null
    canvasAndContext.context = null
  }
}

export interface TextAnalysisResult {
  embedding: number[]
  modelName: string
  confidence: number
  processingTime: number
  wordCount: number
  charCount: number
  language?: string
  extractedText: string
  summary?: string
}

export interface TextMetadata {
  size: number
  hash: string
  encoding: string
  wordCount: number
  charCount: number
  language?: string
}

/**
 * AI í…ìŠ¤íŠ¸ ë¶„ì„ê¸°
 * OpenAI Embeddings API ë˜ëŠ” ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ íŠ¹ì§•ì„ ì¶”ì¶œ
 */
export class AITextAnalyzer {
  private isInitialized = false
  private modelName = 'text-embedding-ada-002'
  private apiKey: string | null = null
  private useLocalModel = false
  private localEmbeddingPipeline: any | null = null

  /**
   * ë¶„ì„ê¸° ì´ˆê¸°í™”
   */
  async initialize(): Promise<void> {
    if (this.isInitialized) return

    try {
      console.log('ğŸ“ Initializing AI Text Analyzer...')

      // OpenAI API í‚¤ í™•ì¸
      this.apiKey = process.env.OPENAI_API_KEY || null

      if (this.apiKey) {
        console.log('ğŸ”‘ OpenAI API key found, using cloud embeddings')
        this.modelName = 'text-embedding-ada-002'
        this.useLocalModel = false
      } else {
        console.log('âš ï¸ No OpenAI API key found, using local embeddings')
        this.modelName = 'Xenova/paraphrase-multilingual-MiniLM-L12-v2'
        this.useLocalModel = true
        this.localEmbeddingPipeline = await pipeline(
          'feature-extraction',
          this.modelName
        )
      }

      console.log('âœ… AI Text Analyzer initialized successfully')
      this.isInitialized = true
    } catch (error) {
      console.error('âŒ Failed to initialize AI Text Analyzer:', error)
      throw new Error(
        `Text analyzer initialization failed: ${error instanceof Error ? error.message : String(error)}`
      )
    }
  }

  /**
   * í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ë‚´ìš© ì¶”ì¶œ ë° ì „ì²˜ë¦¬
   */
  private async extractTextContent(filePath: string): Promise<{
    text: string
    metadata: TextMetadata
  }> {
    try {
      // íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
      try {
        await fs.access(filePath)
      } catch (accessError) {
        console.warn(`âš ï¸ File not found, skipping: ${filePath}`)
        return {
          text: '',
          metadata: {
            size: 0,
            hash: '',
            encoding: '',
            wordCount: 0,
            charCount: 0,
          },
        }
      }

      // íŒŒì¼ í†µê³„ ì •ë³´
      const stats = await fs.stat(filePath)

      // íŒŒì¼ ë‚´ìš© ì½ê¸° (ë‹¤ì–‘í•œ ì¸ì½”ë”© ì§€ì›)
      let content = ''
      const ext = path.extname(filePath).toLowerCase()

      if (ext === '.pdf') {
        const dataBuffer = await fs.readFile(filePath)
        try {
          const data = await pdfParse(dataBuffer)
          if (data.text && data.text.trim().length > 0) {
            content = data.text
          }
        } catch (pdfParseError) {
          console.warn(`âš ï¸ pdf-parse failed for ${filePath}:`, pdfParseError)
          content = ''
        }

        // í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆë‹¤ë©´ OCR ì‹œë„
        if (!content || content.trim().length === 0) {
          console.log(
            `ğŸ“ pdf-parse found no text, attempting OCR for ${filePath}`
          )
          try {
            content = await this.extractPdfTextWithOcr(dataBuffer)
          } catch (ocrError) {
            console.error(`âŒ OCR failed for ${filePath}:`, ocrError)
            content = '' // OCR ì‹¤íŒ¨ ì‹œ ë¹ˆ ë‚´ìš©ìœ¼ë¡œ ì²˜ë¦¬
          }
        }
      } else {
        // For non-PDF files, read them as plain text
        content = await fs.readFile(filePath, 'utf-8')
      }

      // í…ìŠ¤íŠ¸ ì •ì œ
      const cleanedText = this.preprocessText(content)

      // í•´ì‹œ ê³„ì‚°
      const fileBuffer = await fs.readFile(filePath)
      const fileHash = createHash('md5').update(fileBuffer).digest('hex')

      // ë©”íƒ€ë°ì´í„° ìƒì„±
      const metadata: TextMetadata = {
        size: stats.size,
        hash: fileHash,
        encoding: 'utf-8', // ì¶”ì •
        wordCount: this.countWords(cleanedText),
        charCount: cleanedText.length,
        language: this.detectLanguage(cleanedText),
      }

      return { text: cleanedText, metadata }
    } catch (error) {
      throw new Error(
        `Failed to extract text from ${filePath}: ${error instanceof Error ? error.message : String(error)}`
      )
    }
  }

  /**
   * popplerì˜ pdftotext CLIë¥¼ ì‚¬ìš©í•œ í´ë°± ì¶”ì¶œ (ì„¤ì¹˜ë˜ì–´ ìˆì„ ë•Œë§Œ ë™ì‘)
   */
  private async extractPdfTextWithPdftotext(
    dataBuffer: Buffer
  ): Promise<string> {
    try {
      const { execSync } = await import('child_process')
      // pdftotext ì¡´ì¬ í™•ì¸
      const whichOutput = execSync('which pdftotext', {
        encoding: 'utf8',
        stdio: 'pipe',
      }).trim()
      if (!whichOutput) {
        return ''
      }

      const os = await import('os')
      const tmpdir = os.tmpdir()
      const inputPath = `${tmpdir}/ai-text-${Date.now()}.pdf`
      const outputPath = `${tmpdir}/ai-text-${Date.now()}.txt`
      await fs.writeFile(inputPath, dataBuffer)

      try {
        execSync(
          `pdftotext -enc UTF-8 -layout -q "${inputPath}" "${outputPath}"`,
          {
            encoding: 'utf8',
            stdio: 'pipe',
            timeout: 60000,
          }
        )
      } catch {
        // ë³€í™˜ ì‹¤íŒ¨ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        return ''
      } finally {
        try {
          await fs.rm(inputPath)
        } catch {}
      }

      try {
        const text = await fs.readFile(outputPath, 'utf-8')
        return text || ''
      } finally {
        try {
          await fs.rm(outputPath)
        } catch {}
      }
    } catch {
      return ''
    }
  }

  private async extractPdfTextWithOcr(pdfBuffer: Buffer): Promise<string> {
    const pdfjs = await import('pdfjs-dist/legacy/build/pdf.mjs')

    // í™˜ê²½ì— ë”°ë¼ ì›Œì»¤ ì„¤ì •
    if (typeof window !== 'undefined') {
      // í´ë¼ì´ì–¸íŠ¸ í™˜ê²½: ë³µì‚¬ëœ ì›Œì»¤ íŒŒì¼ ê²½ë¡œ ì§€ì •
      pdfjs.GlobalWorkerOptions.workerSrc =
        '/_next/static/chunks/pdf.worker.mjs'
    }

    const canvasFactory = new NodeCanvasFactory()
    // @ts-ignore
    const loadingTask = pdfjs.getDocument({
      data: new Uint8Array(pdfBuffer),
      disableFontFace: true,
      // ì„œë²„ í™˜ê²½ì—ì„œëŠ” ì›Œì»¤ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë¹„í™œì„±í™”
      disableWorker: typeof window === 'undefined',
      // Node.js í™˜ê²½ì—ì„œ canvasë¥¼ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ íŒ©í† ë¦¬ë¥¼ ì œê³µ
      canvasFactory,
    })
    const pdf = await loadingTask.promise
    const numPages = pdf.numPages
    let fullText = ''

    const worker = await createWorker('kor+eng', OEM.LSTM_ONLY, {
      // logger: (m) => console.log(m), // OCR ì§„í–‰ë¥  ë¡œê¹…
    })
    await worker.setParameters({
      tessedit_pageseg_mode: PSM.AUTO_OSD,
    })

    console.log(`ğŸš€ Starting OCR process for ${numPages} pages...`)

    for (let i = 1; i <= numPages; i++) {
      const page = await pdf.getPage(i)
      const viewport = page.getViewport({ scale: 2.0 }) // í•´ìƒë„ë¥¼ ë†’ì—¬ ì¸ì‹ë¥  í–¥ìƒ
      const { canvas, context } = canvasFactory.create(
        viewport.width,
        viewport.height
      )

      await page.render({ canvasContext: context as any, viewport }).promise
      const imageBuffer = (canvas as Canvas).toBuffer('image/png')

      const {
        data: { text },
      } = await worker.recognize(imageBuffer)
      fullText += text + '\n'
      console.log(`ğŸ” OCR progress: Page ${i}/${numPages} completed.`)

      // ë©”ëª¨ë¦¬ ì •ë¦¬
      page.cleanup()
      canvasFactory.destroy({ canvas, context })
    }

    await worker.terminate()
    console.log('âœ… OCR process finished.')
    return fullText
  }

  /**
   * í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
   */
  private preprocessText(text: string): string {
    return text
      .replace(/\r\n/g, '\n') // Windows ì¤„ë°”ê¿ˆ ì •ê·œí™”
      .replace(/\r/g, '\n') // Mac ì¤„ë°”ê¿ˆ ì •ê·œí™”
      .replace(/\n{3,}/g, '\n\n') // ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì œê±°
      .replace(/\s+/g, ' ') // ì—°ì†ëœ ê³µë°± ì •ê·œí™”
      .trim()
  }

  /**
   * ë‹¨ì–´ ìˆ˜ ê³„ì‚°
   */
  private countWords(text: string): number {
    return text.split(/\s+/).filter((word) => word.length > 0).length
  }

  /**
   * ê°„ë‹¨í•œ ì–¸ì–´ ê°ì§€
   */
  private detectLanguage(text: string): string {
    const sample = text.substring(0, 1000) // ì²˜ìŒ 1000ìë§Œ ìƒ˜í”Œë§

    // í•œê¸€ ë¬¸ì ë¹„ìœ¨
    const koreanChars = (sample.match(/[ê°€-í£]/g) || []).length
    const koreanRatio = koreanChars / sample.length

    // ì˜ì–´ ë¬¸ì ë¹„ìœ¨
    const englishChars = (sample.match(/[a-zA-Z]/g) || []).length
    const englishRatio = englishChars / sample.length

    if (koreanRatio > 0.1) return 'ko'
    if (englishRatio > 0.5) return 'en'
    return 'unknown'
  }

  /**
   * OpenAI Embeddings API í˜¸ì¶œ (ê°œì„ ëœ ë²„ì „)
   */
  private async getOpenAIEmbedding(text: string): Promise<number[]> {
    if (!this.apiKey) {
      throw new Error('OpenAI API key not available')
    }

    try {
      // í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (OpenAI í† í° ì œí•œ ê³ ë ¤)
      const maxTokens = 8000 // ëŒ€ëµ 8000 í† í°
      const truncatedText =
        text.length > maxTokens ? text.substring(0, maxTokens) : text

      console.log(
        `ğŸ”‘ Calling OpenAI API for text embedding (${truncatedText.length} chars)`
      )

      const response = await fetch('https://api.openai.com/v1/embeddings', {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: this.modelName, // text-embedding-ada-002
          input: truncatedText,
          encoding_format: 'float', // ëª…ì‹œì ìœ¼ë¡œ float í˜•ì‹ ìš”ì²­
        }),
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => null)
        const errorMessage =
          errorData?.error?.message ||
          `${response.status} ${response.statusText}`
        throw new Error(`OpenAI API error: ${errorMessage}`)
      }

      const data = await response.json()

      if (!data.data || !data.data[0] || !data.data[0].embedding) {
        throw new Error('Invalid response format from OpenAI API')
      }

      const embedding = data.data[0].embedding
      console.log(
        `âœ… OpenAI embedding received: ${embedding.length} dimensions`
      )

      return embedding
    } catch (error) {
      console.error('âŒ OpenAI API call failed:', error)

      // API ì˜¤ë¥˜ì‹œ ë¡œì»¬ ì„ë² ë”©ìœ¼ë¡œ í´ë°±
      if (
        error instanceof Error &&
        error.message.includes('API') &&
        !error.message.includes('key')
      ) {
        console.warn('ğŸ”„ Falling back to local embedding due to API error')
        return await this.getLocalEmbedding(text)
      }

      throw error
    }
  }

  /**
   * OpenAI API ë°°ì¹˜ ì„ë² ë”© (ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬)
   */
  private async getOpenAIBatchEmbedding(texts: string[]): Promise<number[][]> {
    if (!this.apiKey) {
      throw new Error('OpenAI API key not available')
    }

    try {
      const maxTexts = 100 // OpenAI ë°°ì¹˜ ì œí•œ
      const batchTexts = texts
        .slice(0, maxTexts)
        .map((text) => (text.length > 8000 ? text.substring(0, 8000) : text))

      console.log(`ğŸ”‘ Calling OpenAI Batch API for ${batchTexts.length} texts`)

      const response = await fetch('https://api.openai.com/v1/embeddings', {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: this.modelName,
          input: batchTexts,
          encoding_format: 'float',
        }),
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => null)
        const errorMessage =
          errorData?.error?.message ||
          `${response.status} ${response.statusText}`
        throw new Error(`OpenAI Batch API error: ${errorMessage}`)
      }

      const data = await response.json()

      if (!data.data || !Array.isArray(data.data)) {
        throw new Error('Invalid batch response format from OpenAI API')
      }

      const embeddings = data.data.map((item: any, index: number) => {
        if (!item.embedding) {
          throw new Error(`Missing embedding for text ${index}`)
        }
        return item.embedding
      })

      console.log(
        `âœ… OpenAI batch embeddings received: ${embeddings.length} texts, ${embeddings[0]?.length} dimensions each`
      )

      return embeddings
    } catch (error) {
      console.error('âŒ OpenAI Batch API call failed:', error)

      // ë°°ì¹˜ ì‹¤íŒ¨ì‹œ ê°œë³„ í˜¸ì¶œë¡œ í´ë°±
      console.warn('ğŸ”„ Falling back to individual API calls')
      const results = []
      for (const text of texts) {
        try {
          const embedding = await this.getOpenAIEmbedding(text)
          results.push(embedding)
        } catch (individualError) {
          console.warn(`âš ï¸ Skipping text due to error:`, individualError)
          const localEmbedding = await this.getLocalEmbedding(text)
          results.push(localEmbedding)
        }
      }
      return results
    }
  }

  /**
   * ë¡œì»¬ ì„ë² ë”© ìƒì„± (ê°„ë‹¨í•œ TF-IDF ê¸°ë°˜)
   */
  private async getLocalEmbedding(text: string): Promise<number[]> {
    if (!this.localEmbeddingPipeline) {
      throw new Error(
        'Local embedding pipeline not initialized. Call initialize() first.'
      )
    }

    console.log('ğŸ”„ Generating local text embedding...')

    // í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ëª¨ë¸ ì„±ëŠ¥ ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³ ë ¤)
    const maxLength = 512
    const truncatedText =
      text.length > maxLength ? text.substring(0, maxLength) : text

    const result = await this.localEmbeddingPipeline(truncatedText, {
      pooling: 'mean',
      normalize: true,
    })

    // ê²°ê³¼ í…ì„œì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ì¼ë°˜ ë°°ì—´ë¡œ ë³€í™˜
    const embedding = Array.from(result.data as Float32Array)

    console.log(`âœ… Local embedding generated: ${embedding.length} dimensions`)

    return embedding
  }

  /**
   * ê°„ë‹¨í•œ í•´ì‹œ í•¨ìˆ˜
   */
  private simpleHash(str: string): number {
    let hash = 0
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i)
      hash = (hash << 5) - hash + char
      hash = hash & hash // 32bit ì •ìˆ˜ë¡œ ë³€í™˜
    }
    return hash
  }

  /**
   * í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)
   */
  private generateSummary(text: string): string {
    const sentences = text.split(/[.!?]/).filter((s) => s.trim().length > 10)

    if (sentences.length <= 3) {
      return text.substring(0, 200) + (text.length > 200 ? '...' : '')
    }

    // ì²« ë²ˆì§¸ì™€ ì¤‘ê°„, ë§ˆì§€ë§‰ ë¬¸ì¥ ì„ íƒ
    const summary =
      [
        sentences[0],
        sentences[Math.floor(sentences.length / 2)],
        sentences[sentences.length - 1],
      ].join('. ') + '.'

    return summary.length > 300 ? summary.substring(0, 300) + '...' : summary
  }

  /**
   * í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ
   */
  async extractFeatures(filePath: string): Promise<TextAnalysisResult> {
    if (!this.isInitialized) {
      throw new Error('Text analyzer not initialized. Call initialize() first.')
    }

    const startTime = Date.now()

    try {
      console.log(`ğŸ“„ Analyzing text file: ${path.basename(filePath)}`)

      // í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ
      const { text, metadata } = await this.extractTextContent(filePath)

      console.log(
        `ğŸ“Š Text stats: ${metadata.wordCount} words, ${metadata.charCount} chars, language: ${metadata.language}`
      )

      // ì„ë² ë”© ìƒì„±
      let embedding: number[]
      if (text.trim().length === 0) {
        // ë¹ˆ í…ìŠ¤íŠ¸ì˜ ê²½ìš° 1536ì°¨ì› ì˜ë²¡í„°ë¡œ ëŒ€ì²´í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ìœ ì§€
        embedding = new Array(1536).fill(0)
      } else if (this.useLocalModel) {
        embedding = await this.getLocalEmbedding(text)
      } else {
        embedding = await this.getOpenAIEmbedding(text)
      }

      // ìš”ì•½ ìƒì„±
      const summary = this.generateSummary(text)

      const processingTime = Date.now() - startTime

      console.log(
        `âœ… Text analysis completed: ${path.basename(filePath)} (${processingTime}ms)`
      )

      return {
        embedding,
        modelName: this.modelName,
        confidence: text.trim().length === 0 ? 0.1 : 0.9,
        processingTime,
        wordCount: metadata.wordCount,
        charCount: metadata.charCount,
        language: metadata.language,
        extractedText: text.substring(0, 1000), // ì²˜ìŒ 1000ìë§Œ ì €ì¥
        summary,
      }
    } catch (error) {
      console.error(`âŒ Failed to analyze text file ${filePath}:`, error)
      throw error
    }
  }

  /**
   * í…ìŠ¤íŠ¸ ë¶„ì„ ë° ìºì‹±
   */
  async analyzeAndCache(
    filePath: string,
    fileSize: number,
    fileHash: string
  ): Promise<AIEmbedding> {
    const vectorCache = await getVectorCache()

    // ìºì‹œì—ì„œ ê¸°ì¡´ ì„ë² ë”© í™•ì¸
    const existingEmbedding = await vectorCache.getEmbeddingByPath(filePath)
    if (
      existingEmbedding &&
      existingEmbedding.metadata &&
      existingEmbedding.metadata.hash === fileHash
    ) {
      console.log(
        `ğŸ“‹ Using cached text embedding for: ${path.basename(filePath)}`
      )
      return existingEmbedding
    }

    // ìƒˆë¡œìš´ ë¶„ì„ ìˆ˜í–‰
    const result = await this.extractFeatures(filePath)

    // ë©”íƒ€ë°ì´í„° êµ¬ì„±
    const metadata = {
      size: fileSize,
      hash: fileHash,
      width: 0, // í…ìŠ¤íŠ¸ íŒŒì¼ì—ëŠ” í•´ë‹¹ ì—†ìŒ
      height: 0,
      // í…ìŠ¤íŠ¸ íŠ¹í™” ë©”íƒ€ë°ì´í„°
      wordCount: result.wordCount,
      charCount: result.charCount,
      language: result.language,
      processingTime: result.processingTime,
      confidence: result.confidence,
      summary: result.summary,
    } as any

    // ìºì‹œì— ì €ì¥
    const embedding: AIEmbedding = {
      id: `text_${fileHash}_${Date.now()}`,
      filePath,
      fileType: 'text',
      embedding: result.embedding,
      modelName: result.modelName,
      extractedAt: new Date().toISOString(),
      metadata,
    }

    await vectorCache.saveEmbedding(embedding)
    return embedding
  }

  /**
   * ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ íŒŒì¼ ê²€ìƒ‰
   */
  async findSimilarTexts(
    queryPath: string,
    limit: number = 10,
    threshold: number = 0.7
  ): Promise<
    Array<{
      file: AIEmbedding
      similarity: number
    }>
  > {
    const vectorCache = await getVectorCache()

    // ì¿¼ë¦¬ íŒŒì¼ ë¶„ì„
    const fileStats = await fs.stat(queryPath)
    const fileBuffer = await fs.readFile(queryPath)
    const fileHash = createHash('md5').update(fileBuffer).digest('hex')

    const queryEmbedding = await this.analyzeAndCache(
      queryPath,
      fileStats.size,
      fileHash
    )

    // ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ ê²€ìƒ‰
    const results = await vectorCache.findSimilar(
      queryEmbedding.embedding,
      'text',
      limit + 1,
      threshold
    )

    // ìê¸° ìì‹  ì œì™¸
    return results
      .filter((result) => result.file.filePath !== queryPath)
      .slice(0, limit)
      .map((result) => ({
        file: result.file,
        similarity: result.similarity,
      }))
  }

  /**
   * ë°°ì¹˜ í…ìŠ¤íŠ¸ ë¶„ì„
   */
  async analyzeBatch(
    textPaths: string[],
    progressCallback?: (
      completed: number,
      total: number,
      currentFile: string
    ) => void
  ): Promise<AIEmbedding[]> {
    const results: AIEmbedding[] = []
    const total = textPaths.length

    console.log(`ğŸ“š Starting batch text analysis of ${total} files...`)

    for (let i = 0; i < textPaths.length; i++) {
      const textPath = textPaths[i]

      try {
        if (progressCallback) {
          progressCallback(i, total, textPath)
        }

        // íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
        const fileStats = await fs.stat(textPath)
        const fileBuffer = await fs.readFile(textPath)
        const fileHash = createHash('md5').update(fileBuffer).digest('hex')

        // ë¶„ì„ ë° ìºì‹œ
        const embedding = await this.analyzeAndCache(
          textPath,
          fileStats.size,
          fileHash
        )
        results.push(embedding)

        console.log(
          `âœ… Processed ${i + 1}/${total}: ${path.basename(textPath)}`
        )
      } catch (error) {
        console.error(`âŒ Failed to process ${textPath}:`, error)
        // ì‹¤íŒ¨í•œ íŒŒì¼ì€ ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰
      }
    }

    if (progressCallback) {
      progressCallback(total, total, 'Completed')
    }

    console.log(
      `ğŸ Batch text analysis completed: ${results.length}/${total} files processed`
    )
    return results
  }

  /**
   * ëª¨ë¸ ì •ë³´ ë°˜í™˜
   */
  getModelInfo(): {
    name: string
    isInitialized: boolean
    useLocalModel: boolean
  } {
    return {
      name: this.modelName,
      isInitialized: this.isInitialized,
      useLocalModel: this.useLocalModel,
    }
  }

  /**
   * ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  dispose(): void {
    console.log('ğŸ§¹ Disposing text analyzer resources...')
    this.isInitialized = false
    this.localEmbeddingPipeline = null
  }
}

// ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
let globalTextAnalyzer: AITextAnalyzer | null = null

export async function getTextAnalyzer(): Promise<AITextAnalyzer> {
  if (!globalTextAnalyzer) {
    globalTextAnalyzer = new AITextAnalyzer()
  }

  // AITextAnalyzer í´ë˜ìŠ¤ì— isInitialized ì†ì„±ì´ ì´ë¯¸ ì¡´ì¬í•¨
  if (!globalTextAnalyzer.getModelInfo().isInitialized) {
    await globalTextAnalyzer.initialize()
  }

  return globalTextAnalyzer
}
