import * as tf from '@tensorflow/tfjs-node'
import { promises as fs } from 'fs'
import sharp from 'sharp'
import { createHash } from 'crypto'
import { getVectorCache, AIEmbedding } from './vector-cache'

export interface ImageAnalysisResult {
  embedding: number[]
  modelName: string
  confidence: number
  processingTime: number
}

export class AIImageAnalyzer {
  private model: tf.LayersModel | null = null
  private modelName = 'mobilenet_v2'
  private isInitialized = false

  /**
   * ëª¨ë¸ ì´ˆê¸°í™”
   */
  async initialize(): Promise<void> {
    if (this.isInitialized) return

    try {
      console.log('ğŸ¤– Loading TensorFlow.js MobileNet model...')

      // MobileNetV2 ëª¨ë¸ ë¡œë”© (ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸)
      this.model = await tf.loadLayersModel(
        'https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v2_1.0_224/model.json'
      )

      console.log('âœ… MobileNet model loaded successfully')
      this.isInitialized = true
    } catch (error) {
      console.error('âŒ Failed to load AI model:', error)
      throw new Error('AI model initialization failed')
    }
  }

  /**
   * ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
   */
  async extractFeatures(imagePath: string): Promise<ImageAnalysisResult> {
    if (!this.model) {
      throw new Error('Model not initialized. Call initialize() first.')
    }

    const startTime = Date.now()

    try {
      // ì´ë¯¸ì§€ ì „ì²˜ë¦¬
      const processedImage = await this.preprocessImage(imagePath)

      // íŠ¹ì§• ì¶”ì¶œ (ë§ˆì§€ë§‰ ë ˆì´ì–´ ì „ ë‹¨ê³„ì—ì„œ)
      const features = await this.extractImageFeatures(processedImage)

      // ë©”ëª¨ë¦¬ ì •ë¦¬
      processedImage.dispose()

      const processingTime = Date.now() - startTime

      console.log(
        `ğŸ¨ Image features extracted: ${imagePath} (${processingTime}ms)`
      )

      return {
        embedding: features,
        modelName: this.modelName,
        confidence: 1.0, // MobileNetì€ confidence ì ìˆ˜ë¥¼ ì§ì ‘ ì œê³µí•˜ì§€ ì•ŠìŒ
        processingTime,
      }
    } catch (error) {
      console.error(`âŒ Failed to extract features from ${imagePath}:`, error)
      throw error
    }
  }

  /**
   * ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (MobileNet ì…ë ¥ í˜•ì‹ì— ë§ê²Œ)
   */
  private async preprocessImage(imagePath: string): Promise<tf.Tensor4D> {
    try {
      // Sharpë¥¼ ì‚¬ìš©í•´ì„œ ì´ë¯¸ì§€ ì½ê¸° ë° ë¦¬ì‚¬ì´ì¦ˆ
      const imageBuffer = await sharp(imagePath)
        .resize(224, 224) // MobileNet ì…ë ¥ í¬ê¸°
        .removeAlpha() // ì•ŒíŒŒ ì±„ë„ ì œê±°
        .raw()
        .toBuffer()

      // Bufferë¥¼ Tensorë¡œ ë³€í™˜
      const tensor = tf.tensor3d(
        new Uint8Array(imageBuffer),
        [224, 224, 3],
        'int32'
      )

      // ì •ê·œí™” (0-255 -> 0-1) ë° ë°°ì¹˜ ì°¨ì› ì¶”ê°€
      const normalized = tensor.cast('float32').div(255.0)
      const batched = normalized.expandDims(0) as tf.Tensor4D

      // ë©”ëª¨ë¦¬ ì •ë¦¬
      tensor.dispose()
      normalized.dispose()

      return batched
    } catch (error) {
      console.error(`Failed to preprocess image ${imagePath}:`, error)
      throw error
    }
  }

  /**
   * MobileNetì—ì„œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
   */
  private async extractImageFeatures(
    imageTensor: tf.Tensor4D
  ): Promise<number[]> {
    if (!this.model) throw new Error('Model not initialized')

    try {
      // MobileNet ì˜ˆì¸¡ ì‹¤í–‰
      const prediction = this.model.predict(imageTensor) as tf.Tensor

      // Global Average Pooling (íŠ¹ì§• ë²¡í„°ë¡œ ë³€í™˜)
      const features = tf.mean(prediction, [1, 2]) // [batch, height, width, channels] -> [batch, channels]

      // í…ì„œë¥¼ JavaScript ë°°ì—´ë¡œ ë³€í™˜
      const featuresArray = await features.data()
      const featuresVector = Array.from(featuresArray)

      // ë©”ëª¨ë¦¬ ì •ë¦¬
      prediction.dispose()
      features.dispose()

      return featuresVector
    } catch (error) {
      console.error('Failed to extract features from tensor:', error)
      throw error
    }
  }

  /**
   * ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„ í›„ ë²¡í„° ìºì‹œì— ì €ì¥
   */
  async analyzeAndCache(
    imagePath: string,
    fileSize: number,
    fileHash: string
  ): Promise<AIEmbedding> {
    try {
      // ê¸°ì¡´ ìºì‹œ í™•ì¸
      const vectorCache = await getVectorCache()
      const embeddingId = this.generateEmbeddingId(imagePath, this.modelName)

      const existingEmbedding = await vectorCache.getEmbeddingByPath(
        imagePath,
        this.modelName
      )
      if (existingEmbedding) {
        console.log(`ğŸ“‹ Using cached embedding for: ${imagePath}`)
        return existingEmbedding
      }

      // ìƒˆë¡œ ë¶„ì„
      console.log(`ğŸ” Analyzing image: ${imagePath}`)
      const result = await this.extractFeatures(imagePath)

      // ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
      const metadata = await this.getImageMetadata(
        imagePath,
        fileSize,
        fileHash
      )

      // AIEmbedding ê°ì²´ ìƒì„±
      const embedding: AIEmbedding = {
        id: embeddingId,
        filePath: imagePath,
        fileType: 'image',
        modelName: result.modelName,
        embedding: result.embedding,
        extractedAt: new Date().toISOString(),
        metadata,
      }

      // ë²¡í„° ìºì‹œì— ì €ì¥
      await vectorCache.saveEmbedding(embedding)

      console.log(`âœ… Image embedding cached: ${imagePath}`)
      return embedding
    } catch (error) {
      console.error(`âŒ Failed to analyze and cache image ${imagePath}:`, error)
      throw error
    }
  }

  /**
   * ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
   */
  private async getImageMetadata(
    imagePath: string,
    fileSize: number,
    fileHash: string
  ) {
    try {
      const metadata = await sharp(imagePath).metadata()
      return {
        width: metadata.width,
        height: metadata.height,
        size: fileSize,
        hash: fileHash,
      }
    } catch (error) {
      console.warn(`Failed to get image metadata for ${imagePath}:`, error)
      return {
        size: fileSize,
        hash: fileHash,
      }
    }
  }

  /**
   * ì„ë² ë”© ID ìƒì„± (íŒŒì¼ ê²½ë¡œ + ëª¨ë¸ëª… ê¸°ë°˜)
   */
  private generateEmbeddingId(filePath: string, modelName: string): string {
    const content = `${filePath}:${modelName}`
    return createHash('md5').update(content).digest('hex')
  }

  /**
   * ìœ ì‚¬í•œ ì´ë¯¸ì§€ ê²€ìƒ‰
   */
  async findSimilarImages(
    queryImagePath: string,
    limit: number = 10,
    threshold: number = 0.7
  ): Promise<{ file: AIEmbedding; similarity: number }[]> {
    try {
      // ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¶„ì„
      const queryResult = await this.extractFeatures(queryImagePath)

      // ë²¡í„° ìºì‹œì—ì„œ ìœ ì‚¬í•œ ì´ë¯¸ì§€ ê²€ìƒ‰
      const vectorCache = await getVectorCache()
      const results = await vectorCache.findSimilar(
        queryResult.embedding,
        'image',
        limit,
        threshold
      )

      return results.map((result) => ({
        file: result.file,
        similarity: result.similarity,
      }))
    } catch (error) {
      console.error(
        `Failed to find similar images for ${queryImagePath}:`,
        error
      )
      throw error
    }
  }

  /**
   * ë°°ì¹˜ ì´ë¯¸ì§€ ë¶„ì„
   */
  async analyzeBatch(
    imagePaths: string[],
    progressCallback?: (
      completed: number,
      total: number,
      currentFile: string
    ) => void
  ): Promise<AIEmbedding[]> {
    const results: AIEmbedding[] = []
    const total = imagePaths.length

    console.log(`ğŸš€ Starting batch analysis of ${total} images...`)

    for (let i = 0; i < imagePaths.length; i++) {
      const imagePath = imagePaths[i]

      try {
        if (progressCallback) {
          progressCallback(i, total, imagePath)
        }

        // íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
        const stats = await fs.stat(imagePath)
        const fileBuffer = await fs.readFile(imagePath)
        const fileHash = createHash('md5').update(fileBuffer).digest('hex')

        // ë¶„ì„ ë° ìºì‹œ
        const embedding = await this.analyzeAndCache(
          imagePath,
          stats.size,
          fileHash
        )
        results.push(embedding)

        console.log(`âœ… Processed ${i + 1}/${total}: ${imagePath}`)
      } catch (error) {
        console.error(`âŒ Failed to process ${imagePath}:`, error)
        // ì‹¤íŒ¨í•œ íŒŒì¼ì€ ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰
      }
    }

    if (progressCallback) {
      progressCallback(total, total, 'Completed')
    }

    console.log(
      `ğŸ Batch analysis completed: ${results.length}/${total} images processed`
    )
    return results
  }

  /**
   * ëª¨ë¸ ì •ë³´ ì¡°íšŒ
   */
  getModelInfo(): { name: string; isInitialized: boolean } {
    return {
      name: this.modelName,
      isInitialized: this.isInitialized,
    }
  }

  /**
   * ë©”ëª¨ë¦¬ ì •ë¦¬
   */
  dispose(): void {
    if (this.model) {
      this.model.dispose()
      this.model = null
    }
    this.isInitialized = false
  }
}

// ì „ì—­ AI ì´ë¯¸ì§€ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
let globalImageAnalyzer: AIImageAnalyzer | null = null

export async function getImageAnalyzer(): Promise<AIImageAnalyzer> {
  if (!globalImageAnalyzer) {
    globalImageAnalyzer = new AIImageAnalyzer()
    await globalImageAnalyzer.initialize()
  }
  return globalImageAnalyzer
}
